{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp97VfrVPVpv"
      },
      "source": [
        "# 1. Librerías & Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCinFr1LPVO5",
        "outputId": "5597ea07-0eca-4fba-cf9b-1c9e10fdf4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=ab1bd4410a1a1f7735e044ab3cc1b4aad0f559d3119b88c489b0563256a289d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zH4iyjyxPeYT"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Uy3cfH_iPh4j"
      },
      "outputs": [],
      "source": [
        "#import neo4j [TO-EDIT]\n",
        "#from neo4j import GraphDatabase\n",
        "#import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "61FWrL1FQC9j",
        "outputId": "6f0155a3-dc41-43b9-b6c1-46fbe61236e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0491c0e8472e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "sc # Elemento que ejecuta toda instrucción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FFiAi4oQNPj"
      },
      "source": [
        "# 2. Neo4j Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GGkPemU0Qp5t"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "6vbD7A2lQ0Sw"
      },
      "outputs": [],
      "source": [
        "graph = [(1,11,2),(1,11,3),(2,11,3),(3,11,2),(3,11,4),(4,11,1),(4,11,2),(4,11,3),(4,12,5),(5,12,1),(5,12,2),(5,12,6), (1,12,2), (2,12,3), (3,12,1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. MapReduce Algorithm Implementation"
      ],
      "metadata": {
        "id": "HEoRsG3Aou1m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbPXryMmSVQM",
        "outputId": "041f902a-3e07-47f5-a9e1-7a69de6e2051"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 11, 2),\n",
              " (1, 11, 3),\n",
              " (2, 11, 3),\n",
              " (3, 11, 2),\n",
              " (3, 11, 4),\n",
              " (4, 11, 1),\n",
              " (4, 11, 2),\n",
              " (4, 11, 3),\n",
              " (4, 12, 5),\n",
              " (5, 12, 1),\n",
              " (5, 12, 2),\n",
              " (5, 12, 6),\n",
              " (1, 12, 2),\n",
              " (2, 12, 3),\n",
              " (3, 12, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "rdd_graph = sc.parallelize(graph)\n",
        "rdd_graph.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "t9dJKE1fVsAw"
      },
      "outputs": [],
      "source": [
        "\n",
        "def hash(n):\n",
        "  \"\"\"\n",
        "  Returns number mod 2. The ouput will be 0 or 1.\n",
        "  \"\"\"\n",
        "  return n % 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "SQgndLX_S5RZ"
      },
      "outputs": [],
      "source": [
        "def get_keys(edge, b_dim, b_set, pattern_dim):\n",
        "  \"\"\"\n",
        "  output: retorna las llaves correspondientes para un vertice.\n",
        "\n",
        "  Idea general: buscamos el par hash_n1,hash_n2 dentro de las posibles\n",
        "  combinaciones dentro del espacio de imagenes de la funcion de hash.\n",
        "  Dentro del for, obtenemos un string con la codificacion de las llaves y luego\n",
        "  verificamos si es una llave candidata para el vertice entregado:\n",
        "\n",
        "  1.  sequence_in_reducer: Si la secuencia 'b1b2' esta en la llave del reducer\n",
        "      codificada como hash(n1)hash(n2) ?, donde ? = 0 o 1, entonces se considerará\n",
        "      el par reducer_key : edge.\n",
        "  2.  edge_case: El otro caso, es para cuando tenemos por ejemplo x = n2 y z = n2\n",
        "      para patrones de 3 vertices.\n",
        "  \"\"\"\n",
        "\n",
        "  hash_n1 = hash(edge[0]) # valor de hash para el nodo 1 = b1\n",
        "  hash_n2 = hash(edge[2]) # valor de hash para el nodo 2 = b2\n",
        "  values = [] # posible keys\n",
        "  sequence = '{}{}'.format(hash_n1, hash_n2)\n",
        "\n",
        "  for i in range(0, b_dim ** pattern_dim):\n",
        "    reducer = ''.join(str(num) for num in b_set[i])\n",
        "    sequence_in_reducer = sequence in reducer\n",
        "    edge_case = reducer[0] == sequence[1] and reducer[pattern_dim - 1] == sequence[0]\n",
        "    if sequence_in_reducer or edge_case:\n",
        "        reducer_key = tuple(int(digit) for digit in reducer)\n",
        "        values.append((reducer_key, edge))\n",
        "\n",
        "  return values\n",
        "\n",
        "\n",
        "def map_phase(rdd, b_dim, b_set, pattern_dim):\n",
        "  \"\"\"\n",
        "  input:\n",
        "    - rdd: RDD del grafo de dimension 'dim'\n",
        "    - b_dim: Cantidad de elementos de las imagenes de la funcion de hash.\n",
        "    - b_set: Imagenes de la funcion de hash.\n",
        "    - pattern_dim: cantidad de nodos del patron de grafo.\n",
        "  ouput: Mapeo de cada arista con respecto a las llaves\n",
        "  \"\"\"\n",
        "\n",
        "  mapped_keys = rdd.flatMap(lambda edge: get_keys(edge, b_dim, b_set, pattern_dim))\n",
        "  reducers = mapped_keys.groupByKey().mapValues(list)\n",
        "  return reducers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_patterns(edges, pattern_dim):\n",
        "  \"\"\"\n",
        "  Funcion que retorna todos los patrones encontrados de la forma\n",
        "  (n1,...,nl) : [[(n1,label,n2), ..., (nl-1,label,nl)], ... ]\n",
        "  donde (n1,...,nl) corresponde a los nodos que forman el patron\n",
        "  y la llave corresponde a los patrones posibles formados por estos nodos\n",
        "  para una etique\n",
        "  \"\"\"\n",
        "  neighbors = get_neighbors(edges)\n",
        "  cycles = find_cycles(edges, neighbors, pattern_dim)\n",
        "  return cycles\n",
        "\n",
        "\n",
        "def get_neighbors(edges):\n",
        "  \"\"\"\n",
        "  Funcion que retorna todas las aristas consecutivas a otras aristas.\n",
        "  Es decir, aristas vecinas.\n",
        "  \"\"\"\n",
        "  neighbors = []\n",
        "  for i in range(len(edges)):\n",
        "    curr_edge = edges[i]\n",
        "    neighbors.append([])\n",
        "    for j in range(len(edges)):\n",
        "      next_edge = edges[j]\n",
        "      if next_edge == curr_edge:\n",
        "        continue\n",
        "      if curr_edge[2] == next_edge[0]:\n",
        "        neighbors[i].append(next_edge)\n",
        "  return neighbors\n",
        "\n",
        "\n",
        "def find_cycles(edges, neighbors, pattern_dim):\n",
        "    \"\"\"\n",
        "    Funcion que verifica si existe algun grafo ciclico en el grafo de una\n",
        "    dimension pattern_dim. Retorna todos los ciclos encontrados.\n",
        "    \"\"\"\n",
        "    cycles = [] # Lista de ciclos encontrados\n",
        "\n",
        "    for edge in edges: # Por cada arista del grafo\n",
        "        visited = set() # Determinamos las aritas que ya han sido visitadas\n",
        "        # Inicializamos el stack con con la\n",
        "        stack = [(edge, [edge])]\n",
        "        # arista donde empezamos el recorrido\n",
        "\n",
        "        while len(stack):\n",
        "            curr_edge, path = stack.pop() # Extraemos la primera arista del stack\n",
        "            # Recorremos esta arista, por lo que la marcamos como visitada\n",
        "            visited.add(curr_edge)\n",
        "            # Caso 1: Si el camino recorrido actual supera la cantidad de nodos del bgp,\n",
        "            #         descartamos este camino\n",
        "            if len(path) > pattern_dim:\n",
        "                continue\n",
        "            # Caso 2: Si el camino recorrido tiene un largo igual a pattern_dim,\n",
        "            #         y son aristas transitivas, entonces un posible ciclo.\n",
        "            first_node = path[0][0] # primer nodo del camino\n",
        "            last_node = path[-1][2] # ultimo nodo del caminmo\n",
        "            if len(path) == pattern_dim and first_node == last_node:\n",
        "                cycles.append(path)\n",
        "                # Agregamos el camino y seguimos recorriendo\n",
        "                continue\n",
        "            # Si no es ciclico el camino desde el nodo actual,\n",
        "            # entonces iteramos dentro de sus vecinos\n",
        "            for neighbor_edge in neighbors[edges.index(curr_edge)]:\n",
        "                if neighbor_edge not in visited:\n",
        "                    stack.append((neighbor_edge, path + [neighbor_edge]))\n",
        "\n",
        "    return cycles\n",
        "\n",
        "\n",
        "def get_nodes(pattern, pattern_dim):\n",
        "  \"\"\"\n",
        "  Funcion que retorna la tupla con los nodos que forman un ciclo.\n",
        "  \"\"\"\n",
        "  nodes = []\n",
        "  for i in range(pattern_dim):\n",
        "    edge = pattern[i]\n",
        "    nodes.append(edge[0])\n",
        "\n",
        "  return (tuple(sorted(nodes)), tuple(sorted(pattern)))\n",
        "\n",
        "\n",
        "def get_unique_lists(pattern1, pattern2):\n",
        "    \"\"\"\n",
        "    Funcion que elimina patrones de grafo duplicados para cada llave\n",
        "    (n1,n2, ..., nl). Si tenemos l = 3, entonces seria (n1,n2,n3)\n",
        "    \"\"\"\n",
        "    lst = []\n",
        "    if pattern2 != pattern1:\n",
        "      return lst.append(pattern2)\n",
        "    else:\n",
        "      return pattern1\n",
        "\n",
        "\n",
        "def reduce_phase(reducers, pattern_dim):\n",
        "  \"\"\"\n",
        "  input: RDD del grafo y cantidad de nodos del patron de grafo.\n",
        "  \"\"\"\n",
        "  reducers_edges = reducers.map(lambda v: v[1]) \\\n",
        "                            .filter(lambda x: len(x) >= pattern_dim)\n",
        "  patterns = reducers_edges \\\n",
        "            .map(lambda edges: find_patterns(edges, pattern_dim)) \\\n",
        "            .flatMap(list) \\\n",
        "            .map(lambda pattern: get_nodes(pattern, pattern_dim)) \\\n",
        "            .groupByKey().mapValues(lambda v: list(set(v)))\n",
        "\n",
        "\n",
        "  return patterns"
      ],
      "metadata": {
        "id": "E2bNeul2o7p5"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_reduce(rdd_graph, b_dim, b_set, pattern_dim):\n",
        "  \"\"\"\n",
        "  Funcion que simula el algoritmo MapReduce, en donde se distribuye el grafo\n",
        "  en diferentes reducers y luego obtenemos los posibles patrones\n",
        "  de grafos formados combinando las informacion de todos los reducers.\n",
        "  \"\"\"\n",
        "  # Fase de Map: Obtenemos las llaves de cada reducer y el conjunto de aristas mapeados a estas llaves.\n",
        "  reducers = map_phase(rdd_graph, b_dim, b_set, pattern_dim)\n",
        "  # Fase Reduce: Obtenemos todos los posibles patrones de L nodos.\n",
        "  patterns = reduce_phase(reducers, pattern_dim)\n",
        "  return patterns"
      ],
      "metadata": {
        "id": "jzZyF1f3lS5I"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcJZG8CQQQne"
      },
      "source": [
        "# 3. MapReduce Algorithm for Triangles"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para encontrar triangulos dentro de un grafo utilizaremos el algoritmo Map Reduce para parametros b_dim = 2 y L = 3. En este caso, al utilizar la funcion de hash modular, generamos un conjunto de 2 imagenes: {0,1}.\n",
        "\n",
        "Por lo que los posibles reducers son:\n",
        "```markdown\n",
        "REDUCERS = [(0, 0, 0),\n",
        "            (0, 0, 1),\n",
        "            (0, 1, 0),\n",
        "            (0, 1, 1),\n",
        "            (1, 0, 0),\n",
        "            (1, 0, 1),\n",
        "            (1, 1, 0),\n",
        "            (1, 1, 1)]\n",
        "```\n",
        "Las aristas se distribuyen dentro de los reducers, por lo que almacenamos el grafo de manera distribuida.\n",
        "\n",
        "En cada reducer verificamos si las aristas generan triangulos, en el caso que si (formaria un ciclo) se almacenará en una lista y retornaremos los nodos correspondientes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d6qMxtBooGtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension de elementos del conjunto de imagenes de la funcion de hash: |{0,1}|\n",
        "b_0 = 2\n",
        "# Dimension del patron de grafo (triangulo para este caso)\n",
        "l_0 = 3\n",
        "# Conjunto de imagenes de la funcion de hash\n",
        "b_set_0 = list(range(b_0))\n",
        "# Posibles reducers\n",
        "reducers_0 = list(product(b_set_0, repeat=l_0))\n",
        "\n",
        "patterns = map_reduce(rdd_graph, b_0, reducers_0, l_0)\n",
        "patterns.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK8OPRVPn8W-",
        "outputId": "463bf12e-204c-4cf3-9aee-3897ffe8e7c3"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((2, 3, 4),\n",
              "  [((2, 11, 3), (3, 11, 4), (4, 11, 2)),\n",
              "   ((2, 12, 3), (3, 11, 4), (4, 11, 2))]),\n",
              " ((1, 2, 3),\n",
              "  [((1, 12, 2), (2, 12, 3), (3, 12, 1)),\n",
              "   ((1, 11, 2), (2, 11, 3), (3, 12, 1)),\n",
              "   ((1, 11, 2), (2, 12, 3), (3, 12, 1)),\n",
              "   ((1, 12, 2), (2, 11, 3), (3, 12, 1))]),\n",
              " ((1, 3, 4), [((1, 11, 3), (3, 11, 4), (4, 11, 1))])]"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notamos que encontramos los nodos:\n",
        "* (2, 3, 4)\n",
        "* (4, 2, 3)\n",
        "* (1, 3, 4)\n",
        "* (4, 1, 3)"
      ],
      "metadata": {
        "id": "zXCDKBX-peqR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aES7v_zWQZZL"
      },
      "source": [
        "# 4. MapReduce Algorithm for Squares\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "cRsbqVb-Qidy"
      },
      "outputs": [],
      "source": [
        "# Como buscaremos los posibles cuadrados a formar, entonces tendremos l=4 nodos\n",
        "# en el bgp.\n",
        "l_1 = 4\n",
        "b_set_1 = list(range(b_0))\n",
        "reducers_1 = list(product(b_set_1, repeat=l_1))\n",
        "squares_patterns = map_reduce(rdd_graph, b_0, reducers_1, l_1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squares_patterns.collect() # Obtenemos todos los posibles patrones cuadrados sin importar el label."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2D1J4F2qePN",
        "outputId": "767a90c4-b04d-4758-bc56-37a792589ed0"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 2, 3, 4),\n",
              "  [((1, 12, 2), (2, 12, 3), (3, 11, 4), (4, 11, 1)),\n",
              "   ((1, 12, 2), (2, 11, 3), (3, 11, 4), (4, 11, 1)),\n",
              "   ((1, 11, 2), (2, 11, 3), (3, 11, 4), (4, 11, 1)),\n",
              "   ((1, 11, 2), (2, 12, 3), (3, 11, 4), (4, 11, 1))]),\n",
              " ((2, 3, 4, 5),\n",
              "  [((2, 11, 3), (3, 11, 4), (4, 12, 5), (5, 12, 2)),\n",
              "   ((2, 12, 3), (3, 11, 4), (4, 12, 5), (5, 12, 2))]),\n",
              " ((2, 3, 3, 4),\n",
              "  [((2, 11, 3), (3, 11, 2), (3, 11, 4), (4, 11, 3)),\n",
              "   ((2, 12, 3), (3, 11, 2), (3, 11, 4), (4, 11, 3))]),\n",
              " ((1, 3, 4, 5), [((1, 11, 3), (3, 11, 4), (4, 12, 5), (5, 12, 1))]),\n",
              " ((1, 2, 3, 3), [((1, 11, 3), (2, 12, 3), (3, 11, 2), (3, 12, 1))])]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_patterns(pattern, pattern_dim, labels):\n",
        "  satisfy = False\n",
        "  filtered = []\n",
        "  for i in range(pattern_dim):\n",
        "    edge_label = pattern[i][1]\n",
        "    satisfy = True if edge_label == labels[i] else False\n",
        "  if satisfy:\n",
        "    return pattern\n",
        "\n",
        "def bgp_query(rdd_graph, b_dim, reducers, pattern_dim, query):\n",
        "  patterns = map_reduce(rdd_graph, b_dim, reducers, pattern_dim).values().flatMap(list)\n",
        "  processed_query = query.replace(\"(\", \"\").replace(\")\", \"\").split(\",\")\n",
        "  labels = [int(part.strip()) for part in processed_query if part.strip().isdigit()]\n",
        "  result = patterns.filter(lambda pattern: filter_patterns(pattern, pattern_dim, labels))\n",
        "  return result.collect()\n"
      ],
      "metadata": {
        "id": "nOwRVr4FqxgJ"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bgp_query(rdd_graph, b_0, reducers_1, l_1, \"(x,11,y), (y,11,z), (z,11,w), (w,11,x)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7IUXiTUwf9X",
        "outputId": "fb80ded5-cef0-4b0a-af95-ce1f2004ea62"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 12, 2), (2, 12, 3), (3, 11, 4), (4, 11, 1)),\n",
              " ((1, 12, 2), (2, 11, 3), (3, 11, 4), (4, 11, 1)),\n",
              " ((1, 11, 2), (2, 11, 3), (3, 11, 4), (4, 11, 1)),\n",
              " ((1, 11, 2), (2, 12, 3), (3, 11, 4), (4, 11, 1)),\n",
              " ((2, 11, 3), (3, 11, 2), (3, 11, 4), (4, 11, 3)),\n",
              " ((2, 12, 3), (3, 11, 2), (3, 11, 4), (4, 11, 3))]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bgp_query(rdd_graph, b_0, reducers_1, l_1, \"(x,11,y), (y,11,z), (z,12,w), (w,12,x)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi-3j4s8srrK",
        "outputId": "e41c5ff8-42f2-40cf-802b-916209f0a26b"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((2, 11, 3), (3, 11, 4), (4, 12, 5), (5, 12, 2)),\n",
              " ((2, 12, 3), (3, 11, 4), (4, 12, 5), (5, 12, 2)),\n",
              " ((1, 11, 3), (3, 11, 4), (4, 12, 5), (5, 12, 1)),\n",
              " ((1, 11, 3), (2, 12, 3), (3, 11, 2), (3, 12, 1))]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}