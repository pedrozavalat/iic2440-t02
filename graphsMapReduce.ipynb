{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp97VfrVPVpv"
      },
      "source": [
        "# 1. Librerías & Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCinFr1LPVO5",
        "outputId": "61137b67-1f85-4b8d-8e22-5ca3d33e9780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=9865a10fb1cce82e868f8feebdeda84793d1f8cc2f07a4bb03c94b10d1c51a6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zH4iyjyxPeYT"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Uy3cfH_iPh4j"
      },
      "outputs": [],
      "source": [
        "#import neo4j [TO-EDIT]\n",
        "#from neo4j import GraphDatabase\n",
        "#import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "61FWrL1FQC9j",
        "outputId": "e619f00f-554e-4765-acd9-bb734988dfde"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://82f78b88557b:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "sc # Elemento que ejecuta toda instrucción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FFiAi4oQNPj"
      },
      "source": [
        "# 2. Neo4j Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGkPemU0Qp5t"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6vbD7A2lQ0Sw"
      },
      "outputs": [],
      "source": [
        "graph = [(1,11,2),(1,11,3),(2,11,3),(3,11,2),(3,11,4),(4,11,1),(4,11,2),(4,11,3),(4,12,5),(5,12,1),(5,12,2),(5,12,6)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcJZG8CQQQne"
      },
      "source": [
        "# 3. MapReduce Algorithm for Triangles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbPXryMmSVQM",
        "outputId": "f2521d20-4a20-421d-f068-c6901fa7b7e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 11, 2),\n",
              " (1, 11, 3),\n",
              " (2, 11, 3),\n",
              " (3, 11, 2),\n",
              " (3, 11, 4),\n",
              " (4, 11, 1),\n",
              " (4, 11, 2),\n",
              " (4, 11, 3),\n",
              " (4, 12, 5),\n",
              " (5, 12, 1),\n",
              " (5, 12, 2),\n",
              " (5, 12, 6)]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_graph = sc.parallelize(graph)\n",
        "rdd_graph.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "t9dJKE1fVsAw"
      },
      "outputs": [],
      "source": [
        "def hash(number):\n",
        "  \"\"\"\n",
        "  Returns number mod 2. The ouput will be 0 or 1.\n",
        "  \"\"\"\n",
        "  return number % 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQgndLX_S5RZ",
        "outputId": "fe4a61d6-f835-49d8-dd48-72dda6e42bb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((0, 0, 1),\n",
              "  [(1, 11, 2),\n",
              "   (2, 11, 3),\n",
              "   (3, 11, 2),\n",
              "   (3, 11, 4),\n",
              "   (4, 11, 1),\n",
              "   (4, 11, 2),\n",
              "   (4, 11, 3),\n",
              "   (4, 12, 5),\n",
              "   (5, 12, 2),\n",
              "   (5, 12, 6)]),\n",
              " ((0, 1, 0),\n",
              "  [(1, 11, 2),\n",
              "   (2, 11, 3),\n",
              "   (3, 11, 2),\n",
              "   (3, 11, 4),\n",
              "   (4, 11, 1),\n",
              "   (4, 11, 2),\n",
              "   (4, 11, 3),\n",
              "   (4, 12, 5),\n",
              "   (5, 12, 2),\n",
              "   (5, 12, 6)]),\n",
              " ((1, 0, 0),\n",
              "  [(1, 11, 2),\n",
              "   (2, 11, 3),\n",
              "   (3, 11, 2),\n",
              "   (3, 11, 4),\n",
              "   (4, 11, 1),\n",
              "   (4, 11, 2),\n",
              "   (4, 11, 3),\n",
              "   (4, 12, 5),\n",
              "   (5, 12, 2),\n",
              "   (5, 12, 6)]),\n",
              " ((1, 1, 1), [(1, 11, 3), (5, 12, 1)]),\n",
              " ((0, 1, 1),\n",
              "  [(1, 11, 2),\n",
              "   (1, 11, 3),\n",
              "   (2, 11, 3),\n",
              "   (3, 11, 2),\n",
              "   (3, 11, 4),\n",
              "   (4, 11, 1),\n",
              "   (4, 11, 3),\n",
              "   (4, 12, 5),\n",
              "   (5, 12, 1),\n",
              "   (5, 12, 2),\n",
              "   (5, 12, 6)]),\n",
              " ((1, 0, 1),\n",
              "  [(1, 11, 2),\n",
              "   (1, 11, 3),\n",
              "   (2, 11, 3),\n",
              "   (3, 11, 2),\n",
              "   (3, 11, 4),\n",
              "   (4, 11, 1),\n",
              "   (4, 11, 3),\n",
              "   (4, 12, 5),\n",
              "   (5, 12, 1),\n",
              "   (5, 12, 2),\n",
              "   (5, 12, 6)]),\n",
              " ((1, 1, 0),\n",
              "  [(1, 11, 2),\n",
              "   (1, 11, 3),\n",
              "   (2, 11, 3),\n",
              "   (3, 11, 2),\n",
              "   (3, 11, 4),\n",
              "   (4, 11, 1),\n",
              "   (4, 11, 3),\n",
              "   (4, 12, 5),\n",
              "   (5, 12, 1),\n",
              "   (5, 12, 2),\n",
              "   (5, 12, 6)]),\n",
              " ((0, 0, 0), [(4, 11, 2)])]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B = 2 # Dimension de elementos del conjunto de imagenes de la funcion de hash\n",
        "L = 3 # Dimension del subgrafo (triangulo)\n",
        "BSET = list(range(B))\n",
        "REDUCERS = list(product(BSET, repeat=L))\n",
        "\n",
        "def get_keys(edge, b_dim, b_set, pattern_dim):\n",
        "  \"\"\"\n",
        "  Funcion que retorna las llaves correspondientes para un vertice.\n",
        "  - b_dim = dimension del conjunto de imagenes de la funcion de hash (|b|)\n",
        "  - b_set = conjunto de imagenes de la funcion de hash (b)\n",
        "  - pattern_dim = dimension del patron de vertices entregado (l)\n",
        "  - hash_n1 = valor de hash para el nodo 1 = b1\n",
        "  - hash_n2 = valor de hash para el nodo 2 = b2\n",
        "\n",
        "  Idea general: buscamos el par hash_n1,hash_n2 dentro de las posibles\n",
        "  combinaciones dentro del espacio de imagenes de la funcion de hash.\n",
        "  Dentro del for, obtenemos un string con la codificacion de las llaves y luego\n",
        "  verificamos si es una llave candidata para el vertice entregado:\n",
        "  \n",
        "  1.  sequence_in_reducer: Si la secuencia 'b1b2' esta en la llave del reducer\n",
        "      codificada como hash(n1)hash(n2) ?, donde ? = 0 o 1, entonces se considerará\n",
        "      el par reducer_key : edge.\n",
        "  2.  edge_case: El otro caso, es para cuando tenemos por ejemplo x = n2 y z = n2\n",
        "      para patrones de 3 vertices.\n",
        "  \"\"\"\n",
        "\n",
        "  hash_n1 = hash(edge[0])\n",
        "  hash_n2 = hash(edge[2])\n",
        "  values = [] # posible keys\n",
        "  sequence = '{}{}'.format(hash_n1, hash_n2)\n",
        "\n",
        "  for i in range(0, b_dim ** pattern_dim):\n",
        "    reducer = ''.join(str(num) for num in b_set[i])\n",
        "    sequence_in_reducer = sequence in reducer\n",
        "    edge_case = reducer[0] == sequence[1] and reducer[pattern_dim - 1] == sequence[0]\n",
        "    if sequence_in_reducer or edge_case:\n",
        "        reducer_key = tuple(int(digit) for digit in reducer)\n",
        "        values.append((reducer_key, edge))\n",
        "\n",
        "  return values\n",
        "\n",
        "\n",
        "def map_phase(rdd, dim):\n",
        "  \"\"\"\n",
        "  input: RDD del grafo de dimension 'dim'\n",
        "  ouput: Mapeo de cada arista con respecto a las llaves\n",
        "  \"\"\"\n",
        "  mapped_keys = rdd.flatMap(lambda edge: get_keys(edge, dim))\n",
        "  reducers = mapped_keys.groupByKey().mapValues(list)\n",
        "  return reducers\n",
        "\n",
        "def reduce_phase(rdd, dim):\n",
        "  # TODO\n",
        "  pass\n",
        "\n",
        "reducers = map_phase(rdd_graph, 3)\n",
        "reducers.collect()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aES7v_zWQZZL"
      },
      "source": [
        "# 4. MapReduce Algorithm for Squares\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRsbqVb-Qidy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
