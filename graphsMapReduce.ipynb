{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp97VfrVPVpv"
      },
      "source": [
        "# 1. Librerías & Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Instalaremos todas las librerias necesarias para poder trabajar con PySpark y Neo4j"
      ],
      "metadata": {
        "id": "h3AfOYEQTWTC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCinFr1LPVO5",
        "outputId": "55356492-ef2a-42af-f728-7d856f1bebc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=8956e8e4e3d5b5618c31f7e8e9b36be54596fe4a6681047e10ec63ff4c7807e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "metadata": {
        "id": "y3_dX6wSCNrT",
        "outputId": "fb71d0b3-ec41-4acc-ca13-0805b7d717a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neo4j\n",
            "  Downloading neo4j-5.21.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2023.4)\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-5.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "👉🏻"
      ],
      "metadata": {
        "id": "iy_QQnF2Txf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Importaremos los archivos de la base de datos Core para poder trabajar un grafo en Neo4j."
      ],
      "metadata": {
        "id": "iiJnIwNxTyH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/scl/fi/2in2ohw1bgkjzeclauevo/neo4j-graph.zip?rlkey=fb2t2ocmj13me0ietrmmy5ij9&st=hi947a3c&dl=0\n",
        "!mv neo4j-graph.zip?rlkey=fb2t2ocmj13me0ietrmmy5ij9 neo4j-graph.zip\n",
        "!unzip -qq neo4j-graph.zip\n",
        "print('* Bases de datos cargada correctamente *')"
      ],
      "metadata": {
        "id": "4wUN4Jk598kC",
        "outputId": "ef29667b-b138-4021-ea78-942227d5b07c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-15 00:32:41--  https://www.dropbox.com/scl/fi/2in2ohw1bgkjzeclauevo/neo4j-graph.zip?rlkey=fb2t2ocmj13me0ietrmmy5ij9\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.85.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.85.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc5fb1414a467c3411ff075cbbae.dl.dropboxusercontent.com/cd/0/inline/CU1N2VjpEn0lUOtmK38dHJm3OWyFVUdJUIttW1mcL8pYvFVNWv96lV93ZLltj5sdt9BKkF3IO5QrVco540CD6vEURIYjqr197bF-0iTHGxwcPDVBVgKaXKsxFWr2g6ixP35Aib-FVRQ78daEDtZErtKD/file# [following]\n",
            "--2024-06-15 00:32:41--  https://uc5fb1414a467c3411ff075cbbae.dl.dropboxusercontent.com/cd/0/inline/CU1N2VjpEn0lUOtmK38dHJm3OWyFVUdJUIttW1mcL8pYvFVNWv96lV93ZLltj5sdt9BKkF3IO5QrVco540CD6vEURIYjqr197bF-0iTHGxwcPDVBVgKaXKsxFWr2g6ixP35Aib-FVRQ78daEDtZErtKD/file\n",
            "Resolving uc5fb1414a467c3411ff075cbbae.dl.dropboxusercontent.com (uc5fb1414a467c3411ff075cbbae.dl.dropboxusercontent.com)... 162.125.85.15, 2620:100:6020:15::a27d:400f\n",
            "Connecting to uc5fb1414a467c3411ff075cbbae.dl.dropboxusercontent.com (uc5fb1414a467c3411ff075cbbae.dl.dropboxusercontent.com)|162.125.85.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CU1t_IUYP4op9kNxshPkxN3an3evx9vgphWK6D2K9tjb_zf4muaNMH708wgjibYL7nCuoD9Qn921EqANjy4awbm1wLdwaZiqvh69etwZpa4PXQt6uXsJjIdHEbjgHWs5TeZPUQwVL6IGO0bGnWPZwDHlxGSduDD-CP09_aDvghc-HRk9yDsu9yM7IHcMhpGaWxXSmlB-IIO-3r6I-21vX2umPpk4gSdigjRJ7CUtblMEosR-2yVXAN_wHKEDiPRbv7vQFCHEZGxnZC048IxLk4XY268cGQelgnp8zvYC2b7RZUJR4w5oFcKr9Jt7qv_ZUb6elkpwRJ76R3cUSc3xhPNuqKlF9eOgPHJyModJVWhcFvtnajbscxDtH_SDE4RBJWo/file [following]\n",
            "--2024-06-15 00:32:41--  https://uc5fb1414a467c3411ff075cbbae.dl.dropboxusercontent.com/cd/0/inline2/CU1t_IUYP4op9kNxshPkxN3an3evx9vgphWK6D2K9tjb_zf4muaNMH708wgjibYL7nCuoD9Qn921EqANjy4awbm1wLdwaZiqvh69etwZpa4PXQt6uXsJjIdHEbjgHWs5TeZPUQwVL6IGO0bGnWPZwDHlxGSduDD-CP09_aDvghc-HRk9yDsu9yM7IHcMhpGaWxXSmlB-IIO-3r6I-21vX2umPpk4gSdigjRJ7CUtblMEosR-2yVXAN_wHKEDiPRbv7vQFCHEZGxnZC048IxLk4XY268cGQelgnp8zvYC2b7RZUJR4w5oFcKr9Jt7qv_ZUb6elkpwRJ76R3cUSc3xhPNuqKlF9eOgPHJyModJVWhcFvtnajbscxDtH_SDE4RBJWo/file\n",
            "Reusing existing connection to uc5fb1414a467c3411ff075cbbae.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 164336 (160K) [application/zip]\n",
            "Saving to: ‘neo4j-graph.zip?rlkey=fb2t2ocmj13me0ietrmmy5ij9’\n",
            "\n",
            "neo4j-graph.zip?rlk 100%[===================>] 160.48K   495KB/s    in 0.3s    \n",
            "\n",
            "2024-06-15 00:32:42 (495 KB/s) - ‘neo4j-graph.zip?rlkey=fb2t2ocmj13me0ietrmmy5ij9’ saved [164336/164336]\n",
            "\n",
            "replace cora/cora.content? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "* Bases de datos cargada correctamente *\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "zH4iyjyxPeYT"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Uy3cfH_iPh4j"
      },
      "outputs": [],
      "source": [
        "import neo4j\n",
        "from neo4j import GraphDatabase\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos la conexion con la base de datos neo4j Aura.\n",
        "NEO4J_URI = \"neo4j+s://19536020.databases.neo4j.io\"\n",
        "NEO4J_USERNAME = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"p5OV31XQmeiAZnsmh-YSOO4RGastE_ueh1uZ3M81dvk\"\n",
        "AUTH = (NEO4J_USERNAME, NEO4J_PASSWORD)\n",
        "\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=AUTH)\n",
        "with driver.session() as session:\n",
        "    try:\n",
        "        session.run(\"RETURN 1\")\n",
        "        print(\"Connection to Neo4j established successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to connect to Neo4j: {e}\")\n"
      ],
      "metadata": {
        "id": "ayvVtWrCC97K",
        "outputId": "f222da13-1f5a-4203-9032-1bba352e9a88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection to Neo4j established successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciamos una sesion en PySpark\n",
        "spark = SparkSession.builder \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "metadata": {
        "id": "8FvKEocnD3-8",
        "outputId": "816361d6-068c-4264-a0d2-b66e20bedc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://975ee9d99c87:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FFiAi4oQNPj"
      },
      "source": [
        "# 2. Neo4j Graphs and others examples"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Las siguientes funciones permiten cargar grafos de ejemplos para poder realizar las consultas de los patrones de grafo.\n",
        "\n",
        "👉🏻 Existe la funcion create_neo4j_graph para poder cargar una base de datos en Neo4j y luego obtener las aristas existentes de este grafo.\n",
        "\n",
        "👉🏻 Existe la funcion load_graph para poder seleccionar el grafo que queremos realizar las consultas."
      ],
      "metadata": {
        "id": "G-ByrvaJUXEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_neo4j_graph():\n",
        "  \"\"\"\n",
        "  Funcion para cargar la base de datos 'Core' como primer ejemplo de grafo en Neo4j.\n",
        "  \"\"\"\n",
        "  cites = pd.read_csv( # Cargamos los papers que citan a otros papers\n",
        "      'cora/cora.cites', sep = '\\t', header = None, names = ['target', 'source']\n",
        "  )\n",
        "  column_names = [\"paper_id\"] + [f\"word_{idx}\" for idx in range(1433)] + [\"subject\"]\n",
        "  papers = pd.read_csv( # Cargamos el contenido de cada paper\n",
        "      'cora/cora.content', sep = \"\\t\", names = column_names,\n",
        "  )\n",
        "  subjects = papers[[\"paper_id\",\"subject\"]]\n",
        "\n",
        "  with driver.session() as session:\n",
        "    # cargamos todos los papers como nodos ...\n",
        "    query_load_papers = \"\"\"\n",
        "    UNWIND $nodes AS row\n",
        "    MERGE (p:Paper {id: row.paper_id})\n",
        "    SET p.subject = row.subject;\n",
        "    \"\"\"\n",
        "    session.run(query_load_papers, nodes = subjects.to_dict('records'))\n",
        "    # cargamos las relaciones entre papers mediante segun el label \"CITES\" ...\n",
        "    query_load_relationships = \"\"\"\n",
        "    UNWIND $edges AS row\n",
        "    MATCH (p1:Paper {id: row.source})\n",
        "    MATCH (p2:Paper {id: row.target})\n",
        "    MERGE (p1)-[:CITES]->(p2);\n",
        "    \"\"\"\n",
        "    session.run(query_load_relationships, edges = cites.to_dict('records'))\n",
        "    # Ya con el cargado en neo4j, obtenemos todas las relaciones\n",
        "    query_get_edges = \"\"\"\n",
        "    MATCH (node1:Paper)-[label:CITES]->(node2:Paper)\n",
        "    RETURN node1.id AS id_n1, type(label) AS label, node2.id AS id_n2\n",
        "    \"\"\"\n",
        "    result = session.run(query_get_edges)\n",
        "    df_edges = pd.DataFrame(result.data())\n",
        "    # Obtenemos el grafo en formado [(nodo1, label, nodo2), ...]\n",
        "    neo4f_graph = [(item[0], item[1], item[2]) for item in df_edges.values]\n",
        "\n",
        "    return neo4f_graph\n"
      ],
      "metadata": {
        "id": "CIpVKqtWCjMw"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_graph(option):\n",
        "  \"\"\"\n",
        "  Funcion que selecciona el grafo de ejemplo, retorna una lista de tuplas\n",
        "  de las aristas del grafo.\n",
        "  \"\"\"\n",
        "  if option == \"neo4j-graph\":\n",
        "    neo4f_graph = create_neo4j_graph()\n",
        "    return neo4f_graph\n",
        "\n",
        "  elif option == \"basic-example\":\n",
        "    return [\n",
        "        (1,11,2), (1,11,3), (2,11,3), (3,11,2),\n",
        "        (3,11,4), (4,11,1), (4,11,2), (4,11,3),\n",
        "        (4,12,5), (5,12,1), (5,12,2), (5,12,6),\n",
        "        (1,12,2), (2,12,3), (3,12,1)\n",
        "    ]\n",
        "  else:\n",
        "    print(\"La opcion no existe :(\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "utX2DdBh-qUr"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. MapReduce Algorithm Implementation"
      ],
      "metadata": {
        "id": "HEoRsG3Aou1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Las siguientes funciones permiten desarrollar el algoritmo MapReduce implementado con PySpark"
      ],
      "metadata": {
        "id": "kpnJs3fcVGV4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "t9dJKE1fVsAw"
      },
      "outputs": [],
      "source": [
        "def hash(n):\n",
        "  \"\"\"\n",
        "  Returns number mod 2. The ouput will be 0 or 1.\n",
        "  \"\"\"\n",
        "  return n % 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Las funciones siguientes permiten simular la fase de mapeo del algoritmo."
      ],
      "metadata": {
        "id": "oP9Jxlw4VsTe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "SQgndLX_S5RZ"
      },
      "outputs": [],
      "source": [
        "def get_keys(edge, b_dim, b_set, pattern_dim):\n",
        "  \"\"\"\n",
        "  output: retorna las llaves correspondientes para un vertice.\n",
        "\n",
        "  Idea general: buscamos el par hash_n1,hash_n2 dentro de las posibles\n",
        "  combinaciones dentro del espacio de imagenes de la funcion de hash.\n",
        "  Dentro del for, obtenemos un string con la codificacion de las llaves y luego\n",
        "  verificamos si es una llave candidata para el vertice entregado:\n",
        "\n",
        "  1.  sequence_in_reducer: Si la secuencia 'b1b2' esta en la llave del reducer\n",
        "      codificada como hash(n1)hash(n2) ?, donde ? = 0 o 1, entonces se considerará\n",
        "      el par reducer_key : edge.\n",
        "  2.  edge_case: El otro caso, es para cuando tenemos por ejemplo x = n2 y z = n2\n",
        "      para patrones de 3 vertices.\n",
        "  \"\"\"\n",
        "\n",
        "  hash_n1 = hash(edge[0]) # valor de hash para el nodo 1 = b1\n",
        "  hash_n2 = hash(edge[2]) # valor de hash para el nodo 2 = b2\n",
        "  values = [] # posible keys\n",
        "  sequence = '{}{}'.format(hash_n1, hash_n2)\n",
        "\n",
        "  for i in range(0, b_dim ** pattern_dim):\n",
        "    reducer = ''.join(str(num) for num in b_set[i])\n",
        "    sequence_in_reducer = sequence in reducer\n",
        "    edge_case = reducer[0] == sequence[1] and reducer[pattern_dim - 1] == sequence[0]\n",
        "    if sequence_in_reducer or edge_case:\n",
        "        reducer_key = tuple(int(digit) for digit in reducer)\n",
        "        values.append((reducer_key, edge))\n",
        "\n",
        "  return values\n",
        "\n",
        "\n",
        "def map_phase(rdd, b_dim, b_set, pattern_dim):\n",
        "  \"\"\"\n",
        "  input:\n",
        "    - rdd: RDD del grafo de dimension 'dim'\n",
        "    - b_dim: Cantidad de elementos de las imagenes de la funcion de hash.\n",
        "    - b_set: Imagenes de la funcion de hash.\n",
        "    - pattern_dim: cantidad de nodos del patron de grafo.\n",
        "  ouput: Mapeo de cada arista con respecto a las llaves\n",
        "  \"\"\"\n",
        "\n",
        "  mapped_keys = rdd.flatMap(lambda edge: get_keys(edge, b_dim, b_set, pattern_dim))\n",
        "  reducers = mapped_keys.groupByKey().mapValues(list)\n",
        "  return reducers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Las siguientes funciones permiten simular la fase de reduce del algoritmo."
      ],
      "metadata": {
        "id": "LJwFdiz1Vxex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_patterns(edges, pattern_dim):\n",
        "    \"\"\"\n",
        "    Funcion que retorna todos los patrones encontrados de la forma\n",
        "    (n1,...,nl) : [[(n1,label,n2), ..., (nl-1,label,nl)], ... ]\n",
        "    donde (n1,...,nl) corresponde a los nodos que forman el patron\n",
        "    y la llave corresponde a los patrones posibles formados por estos nodos\n",
        "    para una etique\n",
        "    \"\"\"\n",
        "    neighbors = get_neighbors(edges)\n",
        "    cycles = find_cycles(edges, neighbors, pattern_dim)\n",
        "    return cycles\n",
        "\n",
        "\n",
        "def get_neighbors(edges):\n",
        "    \"\"\"\n",
        "    Funcion que retorna todas las aristas consecutivas a otras aristas.\n",
        "    Es decir, aristas vecinas.\n",
        "    \"\"\"\n",
        "    neighbors = []\n",
        "    for i in range(len(edges)):\n",
        "        curr_edge = edges[i]\n",
        "        neighbors.append([])\n",
        "        for j in range(len(edges)):\n",
        "            next_edge = edges[j]\n",
        "            if next_edge == curr_edge:\n",
        "                continue\n",
        "            if curr_edge[2] == next_edge[0]:\n",
        "                neighbors[i].append(next_edge)\n",
        "    return neighbors\n",
        "\n",
        "\n",
        "def find_cycles(edges, neighbors, pattern_dim):\n",
        "    \"\"\"\n",
        "    Funcion que verifica si existe algun grafo ciclico en el grafo de una\n",
        "    dimension pattern_dim. Retorna todos los ciclos encontrados.\n",
        "    Utilizamos el algoritmo DFS iterativo para la busqueda de ciclos.\n",
        "    \"\"\"\n",
        "    cycles = [] # Lista de ciclos encontrados\n",
        "\n",
        "    for edge in edges: # Por cada arista del grafo\n",
        "        visited = set() # Determinamos las aritas que ya han sido visitadas\n",
        "        # Inicializamos el stack con con la\n",
        "        stack = [(edge, [edge])]\n",
        "        # arista donde empezamos el recorrido\n",
        "\n",
        "        while len(stack):\n",
        "            curr_edge, path = stack.pop() # Extraemos la primera arista del stack\n",
        "            # Recorremos esta arista, por lo que la marcamos como visitada\n",
        "            visited.add(curr_edge)\n",
        "            # Caso 1: Si el camino recorrido actual supera la cantidad de nodos del bgp,\n",
        "            #         descartamos este camino\n",
        "            if len(path) > pattern_dim:\n",
        "                continue\n",
        "            # Caso 2: Si el camino recorrido tiene un largo igual a pattern_dim,\n",
        "            #         y son aristas transitivas, entonces un posible ciclo.\n",
        "            first_node = path[0][0] # primer nodo del camino\n",
        "            last_node = path[-1][2] # ultimo nodo del caminmo\n",
        "            if len(path) == pattern_dim and first_node == last_node:\n",
        "                cycles.append(path)\n",
        "                # Agregamos el camino y seguimos recorriendo\n",
        "                continue\n",
        "            # Si no es ciclico el camino desde el nodo actual,\n",
        "            # entonces iteramos dentro de sus vecinos\n",
        "            for neighbor_edge in neighbors[edges.index(curr_edge)]:\n",
        "                if neighbor_edge not in visited:\n",
        "                    stack.append((neighbor_edge, path + [neighbor_edge]))\n",
        "\n",
        "    return cycles\n",
        "\n",
        "\n",
        "def get_nodes(pattern, pattern_dim):\n",
        "    \"\"\"\n",
        "    Funcion que retorna la tupla con los nodos que forman un ciclo.\n",
        "    \"\"\"\n",
        "    nodes = []\n",
        "    for i in range(pattern_dim):\n",
        "      edge = pattern[i]\n",
        "      nodes.append(edge[0])\n",
        "\n",
        "    return (tuple(sorted(nodes)), tuple(sorted(pattern)))\n",
        "\n",
        "\n",
        "def get_unique_lists(pattern1, pattern2):\n",
        "    \"\"\"\n",
        "    Funcion que elimina patrones de grafo duplicados para cada llave\n",
        "    (n1,n2, ..., nl). Si tenemos l = 3, entonces seria (n1,n2,n3)\n",
        "    \"\"\"\n",
        "    lst = []\n",
        "    if pattern2 != pattern1:\n",
        "      return lst.append(pattern2)\n",
        "    else:\n",
        "      return pattern1\n",
        "\n",
        "\n",
        "def reduce_phase(reducers, pattern_dim):\n",
        "    \"\"\"\n",
        "    input: RDD del grafo y cantidad de nodos del patron de grafo.\n",
        "    output: patrones encontrados.\n",
        "    \"\"\"\n",
        "    reducers_edges = reducers.map(lambda v: v[1]) \\\n",
        "                              .filter(lambda x: len(x) >= pattern_dim)\n",
        "    patterns = reducers_edges \\\n",
        "              .map(lambda edges: find_patterns(edges, pattern_dim)) \\\n",
        "              .flatMap(list) \\\n",
        "              .map(lambda pattern: get_nodes(pattern, pattern_dim)) \\\n",
        "              .groupByKey().mapValues(lambda v: list(set(v)))\n",
        "\n",
        "\n",
        "    return patterns"
      ],
      "metadata": {
        "id": "E2bNeul2o7p5"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Funcion final que simula el algoritmo MapReduce. Recibe los parametros correspondientes del grafo; las dimensiones del conjunto de imagenes de la funcion de hash; el conjunto de imagenes de la funcion de hash; la dimension del patron de grafo."
      ],
      "metadata": {
        "id": "6C9TSq9OV4Au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_reduce(rdd_graph, b_dim, b_set, pattern_dim):\n",
        "  \"\"\"\n",
        "  Funcion que simula el algoritmo MapReduce, en donde se distribuye el grafo\n",
        "  en diferentes reducers y luego obtenemos los posibles patrones\n",
        "  de grafos formados combinando las informacion de todos los reducers.\n",
        "  \"\"\"\n",
        "  # Fase de Map: Obtenemos las llaves de cada reducer y el conjunto de aristas mapeados a estas llaves.\n",
        "  reducers = map_phase(rdd_graph, b_dim, b_set, pattern_dim)\n",
        "  # Fase Reduce: Obtenemos todos los posibles patrones de L nodos.\n",
        "  patterns = reduce_phase(reducers, pattern_dim)\n",
        "  return patterns"
      ],
      "metadata": {
        "id": "jzZyF1f3lS5I"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Aplicacion MapReduce en Ejemplo Basico"
      ],
      "metadata": {
        "id": "i7mlfvf9Q6gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 En esta seccion aplicaremos el algoritmo MapReduce para un grafo de prueba pequeño (el que fue dado al inicio de la tarea, con algunas modificaciones). Este lo guardamos como 'basic-example'."
      ],
      "metadata": {
        "id": "L0SJtu5EWJyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = load_graph('basic-example')\n",
        "rdd_graph = sc.parallelize(graph)\n",
        "rdd_graph.collect()"
      ],
      "metadata": {
        "id": "sp8fBluSQ54M",
        "outputId": "5b192492-b2ac-4dec-b1e9-3fbfa34af015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 11, 2),\n",
              " (1, 11, 3),\n",
              " (2, 11, 3),\n",
              " (3, 11, 2),\n",
              " (3, 11, 4),\n",
              " (4, 11, 1),\n",
              " (4, 11, 2),\n",
              " (4, 11, 3),\n",
              " (4, 12, 5),\n",
              " (5, 12, 1),\n",
              " (5, 12, 2),\n",
              " (5, 12, 6),\n",
              " (1, 12, 2),\n",
              " (2, 12, 3),\n",
              " (3, 12, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcJZG8CQQQne"
      },
      "source": [
        "## 3.1 MapReduce Algorithm for Triangles"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Para encontrar triangulos dentro de un grafo utilizaremos el algoritmo Map Reduce para parametros b_0 = 2 y l = 3.\n",
        "\n",
        "👉🏻 En este caso, b_0=2 ya que al utilizar la funcion de hash modular `f(x) = x mod 2`, generamos un conjunto de 2 imagenes: {0,1}. En consecuencia, los posibles reducers son:\n",
        "```markdown\n",
        "REDUCERS = [(0, 0, 0),\n",
        "            (0, 0, 1),\n",
        "            (0, 1, 0),\n",
        "            (0, 1, 1),\n",
        "            (1, 0, 0),\n",
        "            (1, 0, 1),\n",
        "            (1, 1, 0),\n",
        "            (1, 1, 1)]\n",
        "```\n",
        "\n",
        "👉🏻 Dado que estamos buscando subgrafos de 3 nodos, entonces l_0 = 3.\n",
        "\n",
        "👉🏻 Las aristas se distribuyen dentro de los reducers, por lo que almacenamos el grafo de manera distribuida.En cada reducer verificamos si las aristas generan triangulos, en el caso que si (formaria un ciclo) se almacenará en una lista y retornaremos los nodos correspondientes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d6qMxtBooGtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension de elementos del conjunto de imagenes de la funcion de hash: |{0,1}|\n",
        "b_0 = 2\n",
        "# Dimension del patron de grafo (triangulo para este caso)\n",
        "l_0 = 3\n",
        "# Conjunto de imagenes de la funcion de hash\n",
        "b_set_0 = list(range(b_0))\n",
        "# Posibles reducers\n",
        "reducers_0 = list(product(b_set_0, repeat=l_0))\n",
        "\n",
        "patterns = map_reduce(rdd_graph, b_0, reducers_0, l_0)\n",
        "\n",
        "patterns.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK8OPRVPn8W-",
        "outputId": "bdfe8d29-030b-4222-cc79-464f0b3a8c31"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((2, 3, 4),\n",
              "  [((2, 11, 3), (3, 11, 4), (4, 11, 2)),\n",
              "   ((2, 12, 3), (3, 11, 4), (4, 11, 2))]),\n",
              " ((1, 2, 3),\n",
              "  [((1, 12, 2), (2, 12, 3), (3, 12, 1)),\n",
              "   ((1, 11, 2), (2, 11, 3), (3, 12, 1)),\n",
              "   ((1, 11, 2), (2, 12, 3), (3, 12, 1)),\n",
              "   ((1, 12, 2), (2, 11, 3), (3, 12, 1))]),\n",
              " ((1, 3, 4), [((1, 11, 3), (3, 11, 4), (4, 11, 1))])]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Al aplicar el algoritmo mapReduce, podemos notar que existen 3 tripletas de nodos que forman un triangulo. En donde estos nodos permiten formar diferentes patrones de grafos triangulares. En este caso, como tenemos mas de una etiqueta distinta, podemos notar que para una tripleta de nodo, forman mas de un triangulo.\n",
        "```markdown\n",
        "  (2,3,4); (1,2,3); (1,3,4)\n",
        "```\n",
        "\n",
        "👉🏻 Las siguientes funciones se definiran con el fin de desarrollar consultas sobre estos grafos.\n"
      ],
      "metadata": {
        "id": "MCtX0wRxW4TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_patterns(pattern, pattern_dim, labels):\n",
        "  \"\"\"\n",
        "  Funcion que retorna los patrones filtrados segun el label proporcionado como\n",
        "  parametro.\n",
        "  \"\"\"\n",
        "  pattern_labels = [edge[1] for edge in pattern]\n",
        "  for i in range(pattern_dim + 1):\n",
        "      # verificamos si coinciden los labels ...\n",
        "      if pattern_labels == labels:\n",
        "        return pattern\n",
        "      # Hacemos un desplazamiento hacia la derecha ...\n",
        "      pattern_labels = pattern_labels[i:] + pattern_labels[:i]\n",
        "\n",
        "  return None\n",
        "\n",
        "def bgp_query(rdd_graph, b_dim, reducers, pattern_dim, query):\n",
        "  \"\"\"\n",
        "  Funcion que retorna todos los patrones de grafos de dimension \"pattern_dim\"\n",
        "  que coincidan segun la query entregada.\n",
        "  \"\"\"\n",
        "  patterns = map_reduce(rdd_graph, b_dim, reducers, pattern_dim).values().flatMap(list)\n",
        "  processed_query = query.replace(\"(\", \"\").replace(\")\", \"\").split(\",\")\n",
        "  labels = [int(part.strip()) for part in processed_query if part.strip().isdigit()]\n",
        "\n",
        "  result = patterns.filter(lambda pattern: filter_patterns(pattern, pattern_dim, labels))\n",
        "  for res in result.collect():\n",
        "    print(res)"
      ],
      "metadata": {
        "id": "H8MNUFa8XUDZ"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos la siguiente consulta en donde queremos obtener todos los triangulos\n",
        "# donde la etiqueta es 11, independiente del nodo.\n",
        "bgp_query(rdd_graph, b_0, reducers_0, l_0, \"(x,11,y), (y,11,z), (z,11,w)\")"
      ],
      "metadata": {
        "id": "rNlZTxSQXs6x",
        "outputId": "17000462-c5b7-48cb-eabd-486b3a099f07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((2, 11, 3), (3, 11, 4), (4, 11, 2))\n",
            "((1, 11, 3), (3, 11, 4), (4, 11, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aES7v_zWQZZL"
      },
      "source": [
        "## 3.2 MapReduce Algorithm for Squares\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Ahora aplicaremos nuestro algoritmo para la busqueda de patrones de grafos de 4 variables. En primer lugar, utilizaremos el mismo algoritmo anterior, pero cambiaremos los parametros de l y b_set. En este caso, utilizaremos l = 4. En consecuencia, obtenemos una cantidad de $2^4$ reducers (definidos como `reducers_1`)."
      ],
      "metadata": {
        "id": "yBBJpfYRY7C0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "cRsbqVb-Qidy",
        "outputId": "d73bf8f8-01b3-4154-e68e-484f989e27f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 2, 3, 4),\n",
              "  [((1, 12, 2), (2, 12, 3), (3, 11, 4), (4, 11, 1)),\n",
              "   ((1, 12, 2), (2, 11, 3), (3, 11, 4), (4, 11, 1)),\n",
              "   ((1, 11, 2), (2, 11, 3), (3, 11, 4), (4, 11, 1)),\n",
              "   ((1, 11, 2), (2, 12, 3), (3, 11, 4), (4, 11, 1))]),\n",
              " ((2, 3, 4, 5),\n",
              "  [((2, 11, 3), (3, 11, 4), (4, 12, 5), (5, 12, 2)),\n",
              "   ((2, 12, 3), (3, 11, 4), (4, 12, 5), (5, 12, 2))]),\n",
              " ((2, 3, 3, 4),\n",
              "  [((2, 11, 3), (3, 11, 2), (3, 11, 4), (4, 11, 3)),\n",
              "   ((2, 12, 3), (3, 11, 2), (3, 11, 4), (4, 11, 3))]),\n",
              " ((1, 3, 4, 5), [((1, 11, 3), (3, 11, 4), (4, 12, 5), (5, 12, 1))]),\n",
              " ((1, 2, 3, 3), [((1, 11, 3), (2, 12, 3), (3, 11, 2), (3, 12, 1))])]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "# Como buscaremos los posibles cuadrados a formar, entonces tendremos l=4 nodos\n",
        "# en el bgp.\n",
        "l_1 = 4\n",
        "# Tendremos b^4 reducers posibles.\n",
        "b_set_1 = list(range(b_0))\n",
        "reducers_1 = list(product(b_set_1, repeat=l_1))\n",
        "# aplicamos el algoritmo para patrones de grafos de l=4 nodos, con 2^4 reducers\n",
        "# y con un conjunto de preimagenes de la funcion de hash {0,1}.\n",
        "squares_patterns = map_reduce(rdd_graph, b_0, reducers_1, l_1)\n",
        "squares_patterns.collect() # Obtenemos todos los posibles patrones cuadrados sin importar el label."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏻 Ahora podemos notar que el algoritmo se demora aproximadamente 1s en correr.\n",
        "\n",
        "👉🏻 Podemos notar que existen 5 tuplas que forman patrones de grafos cuadrilateros (considerando que tenemos diferentes etiquetas, por lo que algunos nodos se repiten, sin embargo se debe a que presentan labels de aristas distintos).\n",
        "\n",
        "```markdown\n",
        "(1,2,3,4), (2,3,4,5), (2,3,3,4), (1,2,4,5), y (1,2,3,3).\n",
        "```"
      ],
      "metadata": {
        "id": "iA8vqrEGaEPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bgp_query(rdd_graph, b_0, reducers_1, l_1, \"(x,11,y), (y,11,z), (z,11,w), (w,11,x)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7IUXiTUwf9X",
        "outputId": "344ce02a-5e2c-4d64-c882-01cec9293f01"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((1, 11, 2), (2, 11, 3), (3, 11, 4), (4, 11, 1))\n",
            "((2, 11, 3), (3, 11, 2), (3, 11, 4), (4, 11, 3))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bgp_query(rdd_graph, b_0, reducers_1, l_1, \"(x,11,y), (y,11,z), (z,12,w), (w,12,x)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi-3j4s8srrK",
        "outputId": "c9b2ac32-c193-4d05-f25c-4d420ee5ce37"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((1, 12, 2), (2, 12, 3), (3, 11, 4), (4, 11, 1))\n",
            "((2, 11, 3), (3, 11, 4), (4, 12, 5), (5, 12, 2))\n",
            "((1, 11, 3), (3, 11, 4), (4, 12, 5), (5, 12, 1))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}